[
  {
    "id": 1,
    "sentence": "so innocent : 3 פורנווווווו !",
    "dicta": {
      "text": "so innocent : 3 פורנווווווו !",
      "tokens": [
        {
          "token": "so",
          "offsets": {
            "start": 0,
            "end": 2
          },
          "syntax": {
            "word": "so",
            "dep_head_idx": 1,
            "dep_func": "advmod",
            "dep_head": "innocent"
          },
          "seg": [
            "so"
          ],
          "lex": "so",
          "morph": {
            "token": "so",
            "pos": "ADV",
            "feats": {},
            "prefixes": [],
            "suffix": false
          }
        },
        {
          "token": "innocent",
          "offsets": {
            "start": 3,
            "end": 11
          },
          "syntax": {
            "word": "innocent",
            "dep_head_idx": -1,
            "dep_func": "root",
            "dep_head": "!"
          },
          "seg": [
            "innocent"
          ],
          "lex": "[BLANK]",
          "morph": {
            "token": "innocent",
            "pos": "X",
            "feats": {},
            "prefixes": [],
            "suffix": false
          }
        },
        {
          "token": ":",
          "offsets": {
            "start": 12,
            "end": 13
          },
          "syntax": {
            "word": ":",
            "dep_head_idx": 3,
            "dep_func": "punct",
            "dep_head": "3"
          },
          "seg": [
            ":"
          ],
          "lex": ":",
          "morph": {
            "token": ":",
            "pos": "PUNCT",
            "feats": {},
            "prefixes": [],
            "suffix": false
          }
        },
        {
          "token": "3",
          "offsets": {
            "start": 14,
            "end": 15
          },
          "syntax": {
            "word": "3",
            "dep_head_idx": 1,
            "dep_func": "nummod",
            "dep_head": "innocent"
          },
          "seg": [
            "3"
          ],
          "lex": "3",
          "morph": {
            "token": "3",
            "pos": "NUM",
            "feats": {},
            "prefixes": [],
            "suffix": false
          }
        },
        {
          "token": "פורנווווווו",
          "offsets": {
            "start": 16,
            "end": 27
          },
          "syntax": {
            "word": "פורנווווווו",
            "dep_head_idx": 1,
            "dep_func": "dep",
            "dep_head": "innocent"
          },
          "seg": [
            "פורנווווווו"
          ],
          "lex": "פורנו",
          "morph": {
            "token": "פורנווווווו",
            "pos": "NOUN",
            "feats": {},
            "prefixes": [],
            "suffix": false
          }
        },
        {
          "token": "!",
          "offsets": {
            "start": 28,
            "end": 29
          },
          "syntax": {
            "word": "!",
            "dep_head_idx": 0,
            "dep_func": "punct",
            "dep_head": "so"
          },
          "seg": [
            "!"
          ],
          "lex": "!",
          "morph": {
            "token": "!",
            "pos": "PUNCT",
            "feats": {},
            "prefixes": [],
            "suffix": false
          }
        }
      ],
      "root_idx": 1,
      "ner_entities": []
    }
  },
  {
    "id": 2,
    "sentence": "!",
    "dicta": {
      "text": "!",
      "tokens": [
        {
          "token": "!",
          "offsets": {
            "start": 0,
            "end": 1
          },
          "syntax": {
            "word": "!",
            "dep_head_idx": -1,
            "dep_func": "root",
            "dep_head": "!"
          },
          "seg": [
            "!"
          ],
          "lex": "!",
          "morph": {
            "token": "!",
            "pos": "PUNCT",
            "feats": {},
            "prefixes": [],
            "suffix": false
          }
        }
      ],
      "root_idx": 0,
      "ner_entities": []
    }
  },
  {
    "id": 3,
    "sentence": "!",
    "dicta": {
      "text": "!",
      "tokens": [
        {
          "token": "!",
          "offsets": {
            "start": 0,
            "end": 1
          },
          "syntax": {
            "word": "!",
            "dep_head_idx": -1,
            "dep_func": "root",
            "dep_head": "!"
          },
          "seg": [
            "!"
          ],
          "lex": "!",
          "morph": {
            "token": "!",
            "pos": "PUNCT",
            "feats": {},
            "prefixes": [],
            "suffix": false
          }
        }
      ],
      "root_idx": 0,
      "ner_entities": []
    }
  },
  {
    "id": 4,
    "sentence": "!",
    "dicta": {
      "text": "!",
      "tokens": [
        {
          "token": "!",
          "offsets": {
            "start": 0,
            "end": 1
          },
          "syntax": {
            "word": "!",
            "dep_head_idx": -1,
            "dep_func": "root",
            "dep_head": "!"
          },
          "seg": [
            "!"
          ],
          "lex": "!",
          "morph": {
            "token": "!",
            "pos": "PUNCT",
            "feats": {},
            "prefixes": [],
            "suffix": false
          }
        }
      ],
      "root_idx": 0,
      "ner_entities": []
    }
  },
  {
    "id": 5,
    "sentence": "!",
    "dicta": {
      "text": "!",
      "tokens": [
        {
          "token": "!",
          "offsets": {
            "start": 0,
            "end": 1
          },
          "syntax": {
            "word": "!",
            "dep_head_idx": -1,
            "dep_func": "root",
            "dep_head": "!"
          },
          "seg": [
            "!"
          ],
          "lex": "!",
          "morph": {
            "token": "!",
            "pos": "PUNCT",
            "feats": {},
            "prefixes": [],
            "suffix": false
          }
        }
      ],
      "root_idx": 0,
      "ner_entities": []
    }
  },
  {
    "id": 6,
    "sentence": "!",
    "dicta": {
      "text": "!",
      "tokens": [
        {
          "token": "!",
          "offsets": {
            "start": 0,
            "end": 1
          },
          "syntax": {
            "word": "!",
            "dep_head_idx": -1,
            "dep_func": "root",
            "dep_head": "!"
          },
          "seg": [
            "!"
          ],
          "lex": "!",
          "morph": {
            "token": "!",
            "pos": "PUNCT",
            "feats": {},
            "prefixes": [],
            "suffix": false
          }
        }
      ],
      "root_idx": 0,
      "ner_entities": []
    }
  }
]